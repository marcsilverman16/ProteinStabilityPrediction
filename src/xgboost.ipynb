{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I have coppied lots of my code from my random forest notebook as I wanted to try XGBoosting on the same data (I should have organzied this better) adn this is why the first coding block is so large as it is doing the data pre-processing and extracition that is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda init\n",
    "!conda activate protein_stability\n",
    "\n",
    "import baseline as bl\n",
    "import numpy as np\n",
    "\n",
    "from PyBioMed import Pyprotein\n",
    "from PyBioMed.PyProtein import CTD\n",
    "\n",
    "train = bl.load_train_data(\"data/train.csv\", val_split=False)\n",
    "test = bl.load_test_data(\"data/test.csv\")\n",
    "\n",
    "train_seq, test_seq = train.sequence, test.sequence     #extract the sequences\n",
    "print(\"test sequence total\",len(train_seq))\n",
    "print(\"train sequence total\",len(test_seq))\n",
    "\n",
    "def get_features(seq_data):\n",
    "    features = [CTD.CalculateC(protein) for protein in seq_data]\n",
    "    filtered_features = [{key: value for key, value in protein_features.items() if key.endswith('C1')} for protein_features in features]\n",
    "\n",
    "    return filtered_features        #I am only testing C1 for now\n",
    "\n",
    "train_features = get_features(train_seq)\n",
    "test_features = get_features(test_seq)\n",
    "print(\"test\",len(train_features))\n",
    "print(\"train\", len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_features)\n",
    "test_df = pd.DataFrame(test_features)\n",
    "train_y = np.array(train.target.values.tolist())\n",
    "train_y_array = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.4, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.4, 0.7, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(train_df, train_y_array)\n",
    "\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_regressor = xgb.XGBRegressor(**best_params)\n",
    "best_xgb_regressor.fit(train_df, train_y_array)\n",
    "\n",
    "predictions = best_xgb_regressor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test.id.values.tolist()\n",
    "\n",
    "with open(\"xgboost.csv\", \"w\") as f:\n",
    "    f.write(\"id,target\\n\")\n",
    "    for id, y in zip(test_id, predictions):\n",
    "        f.write(f\"{id},{y}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_stability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
